{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1227a81-e726-452b-a92e-da661030e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "from scipy import signal \n",
    "from scipy import integrate\n",
    "import re\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\Ilunya\\\\Desktop\\\\python\\\\wav zne\") \n",
    "wdir='.'\n",
    "for (dirpath, dirnames, filenames) in walk(wdir): \n",
    "    print()\n",
    "def FIV3(mas): #calculation of FIV3\n",
    "    ind=0\n",
    "    #FIV3 max\n",
    "    max1=0\n",
    "    max2=0\n",
    "    max3=0\n",
    "    for i in range (0, len(mas)):\n",
    "        if mas[i]>max1:\n",
    "                max1=round(mas[i],5)\n",
    "                idmax1=i\n",
    "                ind=i+1\n",
    "    flag=0\n",
    "    for i in range (ind, len(mas)):\n",
    "        if mas[i]<0: flag=1\n",
    "        if mas[i]>max2 and flag==1:\n",
    "            max2=round(mas[i],5)\n",
    "            idmax2=i\n",
    "            ind=i+1 \n",
    "    flag=0\n",
    "    for i in range (ind, len(mas)):\n",
    "        if mas[i]<0: flag=1\n",
    "        if mas[i]>max3 and flag==1:\n",
    "            max3=round(mas[i],5) \n",
    "            idmax3=i\n",
    "    #FIV3 min \n",
    "    min1=0\n",
    "    min2=0\n",
    "    min3=0\n",
    "    for i in range (0, len(mas),1):\n",
    "        if mas[i]<min1:\n",
    "                min1=round(mas[i],5)\n",
    "                idmin1=i\n",
    "                ind=i+1\n",
    "    flag=0\n",
    "    for i in range (ind, len(mas),1):\n",
    "        if mas[i]>0: flag=1\n",
    "        if mas[i]<min2 and flag==1:\n",
    "            min2=round(mas[i],5)\n",
    "            idmin2=i\n",
    "            ind=i+1 \n",
    "    flag=0\n",
    "    for i in range (ind, len(mas),1):\n",
    "        if mas[i]>0: flag=1\n",
    "        if mas[i]<min3 and flag==1:\n",
    "            min3=round(mas[i],5)  \n",
    "            idmin3=i\n",
    "    FIV3max=round(max1+max2+max3,5)\n",
    "    FIV3min=round(min1+min2+min3,5)\n",
    "    fiv3=max(FIV3max,abs(FIV3min))\n",
    "    return fiv3\n",
    "def PGA(mas): #calculation of PGA ond other measures\n",
    "    maxPGA=0\n",
    "    for i in range(0,len(mas)):\n",
    "        if abs(mas[i])>maxPGA: maxPGA=abs(mas[i])\n",
    "    return maxPGA\n",
    "flag=0\n",
    "data_dict ={}\n",
    "for name in filenames: #accelerogram files\n",
    "    path=name \n",
    "    file = open(path) \n",
    "    strings = file.readlines() \n",
    "    firststring = strings[1].split() \n",
    "    thirdstring = strings[3].split() \n",
    "    file.close()\n",
    "    if \"acceleration\" not in firststring: continue #checking for correctness of files\n",
    "    flag+=1\n",
    "    name=name[:-4]\n",
    "    params=name.split('_') #taking info from filename\n",
    "    M = float(params[-3]) #local magnitude\n",
    "    H = float(params[-2]) #earthquake depth\n",
    "    R = float(params[-1]) #epicentral distance\n",
    "    Date = params[0] #earthquake date\n",
    "    StName = params[1] #station code\n",
    "    StType = params[2] #station type\n",
    "    fiv3=[] #fiv3 massive\n",
    "    PGA #peak ground acceleration\n",
    "    PGV=0.0 #peak ground velocity\n",
    "    Ia=0.0 #Arias intensity\n",
    "    MFAS=[] #raw spectrum\n",
    "    PMFAS=0.0 #peak raw spectrum\n",
    "    freq=[] #frequensy from raw spectrum file\n",
    "    f001=[] #peak raw spectrum (freq=0.01)\n",
    "    f002=[]\n",
    "    f003=[]\n",
    "    f005=[]\n",
    "    f0075=[]\n",
    "    f01=[]\n",
    "    f015=[]\n",
    "    f02=[]\n",
    "    f025=[]\n",
    "    f03=[]\n",
    "    f04=[]\n",
    "    f05=[]\n",
    "    f075=[]\n",
    "    f1=[]\n",
    "    f15=[]\n",
    "    f2=[]\n",
    "    f3=[]\n",
    "    f4=[]\n",
    "    f5=[]\n",
    "    f75=[]\n",
    "    f10=[]\n",
    "    file = open(path)\n",
    "    strings = file.readlines()\n",
    "    thirdstring = strings[3].strip().split()\n",
    "    file.close()\n",
    "    count=round(float(thirdstring[0])/7-7) #count of data in one file\n",
    "    step=float(thirdstring[1])\n",
    "    data=np.loadtxt(path,skiprows=4,max_rows=count).flatten() #taking data from accelerograms\n",
    "    timesMin=np.array([(step*i)/60 for i in range(len(data))]) # taking time and converting from nm to sec\n",
    "    times=np.array([step*i for i in range(len(data))]) \n",
    "\n",
    "    data_dict[name] = [times,data,str(M),str(H),str(R), fiv3, step, Date, StName, StType, PGA, PGV, Ia, RS, PRS, \n",
    "                        #0    1     2       3      4      5      6     7     8        9     10   11  12  13   14\n",
    "                       f001, f002, f003, f005, f0075, f01, f015, f02,\n",
    "                       #15    16    17     18     19   20    21   22    \n",
    "                       f025, f03, f04, f05, f075, f1, f15, f2, f3, f4, f5, f75, f10,\n",
    "                      #23     24   25   26   27   28   29   30  31 32  33   34   35\n",
    "                       MFAS, PMFAS,freq] #dictionary with all data from earthquake\n",
    "                        #36   37   38    \n",
    "os.chdir(\"C:\\\\Users\\\\Ilunya\\\\Desktop\\\\specs\") #taking data from raw spectrum files\n",
    "wdir='.'        \n",
    "for (dirpath, dirnames, filenames) in walk(wdir): \n",
    "    print()\n",
    "for name in filenames: \n",
    "    path=name \n",
    "    file = open(path) \n",
    "    strings = file.readlines() \n",
    "    specs=[] \n",
    "    s=1\n",
    "    for x in strings: \n",
    "        x=re.sub(\" +\", \" \", x)\n",
    "        if s==1:\n",
    "            s=2\n",
    "            continue\n",
    "        specs.append(float(x.split(' ')[2]))\n",
    "    data_dict[name.replace(\".out\", \"\")][36]=specs #add spectum to dictionary\n",
    "    data_dict[name.replace(\".out\", \"\")][38]=freq #add frequensy to dictionary\n",
    "    file.close()\n",
    "for k in data_dict.keys(): \n",
    "    sig = data_dict[k][1]\n",
    "    for i in range(0, len(sig)):\n",
    "        sig[i]*=10**(-7) #converting from nm/s to cm/s\n",
    "    t=data_dict[k][0]\n",
    "    sos = signal.butter(2, 1, 'low', fs=50, output='sos') #2nd order lowpass Butterworth filter with freq=1\n",
    "    filtered = signal.sosfilt(sos, sig)\n",
    "    data_dict[k][10]=round(PGA(data_dict[k][1]),5) #add FIV3 massive to dictionary\n",
    "    integrated=[]\n",
    "    integrated = integrate.cumtrapz(data_dict[k][1], data_dict[k][0], initial=0)\n",
    "    data_dict[k][11]=round(PGA(integrated),5)\n",
    "    FAS=[]\n",
    "    for l in range(0,len(data_dict[k][36])):\n",
    "        FAS.append((10**data_dict[k][36][l])*10**(-9)) #converting from nm/s to m/s\n",
    "    MFAS.append(round(PGA(FAS),3))\n",
    "    data_dict[k][37]=MFAS #add peak raw spectrum to dictionary\n",
    "    integrated=[] #null mass\n",
    "    Ia=[]\n",
    "    mas=[]\n",
    "    PIa=0\n",
    "    g=9.81\n",
    "    deltat=data_dict[k][0][1]+0.2\n",
    "    limit=50\n",
    "    integrated = integrate.cumtrapz((data_dict[k][1]*10**(-2))**2, data_dict[k][0], initial=0) #converting from cm/s to m/s and integrate\n",
    "    for i in range(0,len(integrated)):\n",
    "        mas.append(integrated[i]*np.pi/(2*g)) #use Arias intensity formula\n",
    "    Ia=mas\n",
    "    data_dict[k][12]=PGA(Ia) #add Arias intensity to dictionary\n",
    "    data_dict[k][14]=round(PGA(data_dict[k][13]),5) #add PMFAS to dictionary\n",
    "    T=0.01\n",
    "    integrated=[]\n",
    "    deltat=data_dict[k][0][1]+0.7*T\n",
    "    limit=30 #creating limit for integrating without mistakes\n",
    "    for i in range(0,len(filtered)-limit):\n",
    "        t=data_dict[k][0]\n",
    "        c=0\n",
    "        j=0\n",
    "        sumt=0\n",
    "        while sumt<deltat: #integrating by sum\n",
    "            c+=filtered[i+j]*(t[i+j+1]-t[i+j])\n",
    "            sumt+=t[i+j+1]-t[i+j]\n",
    "            j+=1\n",
    "        integrated.append(c)\n",
    "    data_dict[k][5].append(FIV3(integrated[:-limit])) #add FIV3 T=0.01 to dictionary\n",
    "    T=0.2\n",
    "    integrated=[]\n",
    "    deltat=data_dict[k][0][1]+0.7*T\n",
    "    limit=40 #creating limit bigger because step for sum became higher\n",
    "    for i in range(0,len(filtered)-limit):\n",
    "        t=data_dict[k][0]\n",
    "        c=0\n",
    "        j=0\n",
    "        sumt=0\n",
    "        while sumt<deltat:\n",
    "            c+=filtered[i+j]*(t[i+j+1]-t[i+j])\n",
    "            j+=1\n",
    "            sumt+=t[i+j+1]-t[i+j]\n",
    "        integrated.append(c)\n",
    "    data_dict[k][5].append(FIV3(integrated[:-limit])) #add FIV3 T=0.2 to dictionary\n",
    "    T=1\n",
    "    integrated=[]\n",
    "    deltat=data_dict[k][0][1]+0.7*T\n",
    "    limit=150\n",
    "    for i in range(0,len(filtered)-limit):\n",
    "        t=data_dict[k][0]\n",
    "        c=0\n",
    "        j=0\n",
    "        sumt=0\n",
    "        while sumt<deltat:\n",
    "            c+=filtered[i+j]*(t[i+j+1]-t[i+j])\n",
    "            j+=1\n",
    "            sumt+=t[i+j+1]-t[i+j]\n",
    "        integrated.append(c)\n",
    "    data_dict[k][5].append(FIV3(integrated[:-limit])) #add FIV3 T=1 to dictionary\n",
    "    T=3\n",
    "    integrated=[]\n",
    "    deltat=data_dict[k][0][1]+0.7*T\n",
    "    limit=550\n",
    "    for i in range(0,len(filtered)-limit):\n",
    "        t=data_dict[k][0]\n",
    "        c=0\n",
    "        j=0\n",
    "        sumt=0\n",
    "        while sumt<deltat:\n",
    "            c+=filtered[i+j]*(t[i+j+1]-t[i+j])\n",
    "            j+=1\n",
    "            sumt+=t[i+j+1]-t[i+j]\n",
    "        integrated.append(c)\n",
    "    data_dict[k][5].append(FIV3(integrated[:-limit])) #add FIV3 T=3 to dictionary\n",
    "    fr=data_dict[k][38] \n",
    "    for j in range(0,len(fr)): \n",
    "        if round(fr[j],2)==0.01: data_dict[k][15]=round(FAS[j],6) #add Sa freq=0.01 to dictionary\n",
    "        if round(fr[j],2)==0.02: data_dict[k][16]=round(FAS[j],6) #freq=0.02\n",
    "        if round(fr[j],2)==0.03: data_dict[k][17]=round(FAS[j],6) #freq=0.03\n",
    "        if round(fr[j],2)==0.05: data_dict[k][18]=round(FAS[j],6) #freq=0.05\n",
    "        if round(fr[j],3)>=0.071 and round(fr[j],3)<=0.079: data_dict[k][19]=round(FAS[j],6) #freq=0.075\n",
    "        if round(fr[j],1)==0.1: data_dict[k][20]=round(FAS[j],6) #freq=0.1\n",
    "        if round(fr[j],2)>=0.14 and round(fr[j],2)<=0.16: data_dict[k][21]=round(FAS[j],6) #freq=0.15\n",
    "        if round(fr[j],1)==0.2: data_dict[k][22]=round(FAS[j],6) #freq=0.2\n",
    "        if round(fr[j],2)>=0.24 and round(fr[j],2)<=0.26: data_dict[k][23]=round(FAS[j],6) #freq=0.25\n",
    "        if round(fr[j],1)==0.3: data_dict[k][24]=round(FAS[j],6) #freq=0.3\n",
    "        if round(fr[j],1)==0.4: data_dict[k][25]=round(FAS[j],6) #freq=0.4\n",
    "        if round(fr[j],1)==0.5: data_dict[k][26]=round(FAS[j],6) #freq=0.5\n",
    "        if round(fr[j],2)>=0.73 and round(fr[j],2)<=0.77: data_dict[k][27]=round(FAS[j],6) #freq=0.75\n",
    "        if round(fr[j],1)==1: data_dict[k][28]=round(FAS[j],6) #freq=1\n",
    "        if round(fr[j],1)>=1.4 and round(fr[j],1)<=1.6: data_dict[k][29]=round(FAS[j],6) #freq=1.5\n",
    "        if round(fr[j],1)==2: data_dict[k][30]=round(FAS[j],6) #freq=2\n",
    "        if round(fr[j],1)==3: data_dict[k][31]=round(FAS[j],6) #freq=3\n",
    "        if round(fr[j],1)==4: data_dict[k][32]=round(FAS[j],6) #freq=4\n",
    "        if round(fr[j],1)==5: data_dict[k][33]=round(FAS[j],6) #freq=5\n",
    "        if round(fr[j],1)>=7.4 and round(fr[j],1)<=7.6: data_dict[k][34]=round(FAS[j],6) #freq=7.5\n",
    "        if round(fr[j],1)==10: data_dict[k][35]=round(FAS[j],6) #freq=10\n",
    "os.chdir(\"C:\\\\Users\\\\Ilunya\\\\Desktop\\\\Python\")\n",
    "\n",
    "for i in range(0,len(rData)):\n",
    "    rhyp=round(np.sqrt(rData[i]**2+hData[i]**2),2)\n",
    "    rhData.append(rhyp)\n",
    "    mwData.append(0.05 * mData[i]**3 - 0.64 * mData[i]**2 + 3.5 * mData[i]-2.89)\n",
    "\n",
    "for k in (data_dict.keys()):\n",
    "    rData=np.append(rData,float(data_dict[k][4]))\n",
    "    mData=np.append(mData,float(data_dict[k][2]))\n",
    "    hData=np.append(hData,float(data_dict[k][3]))\n",
    "    f1Data=np.append(f1Data,data_dict[k][5][0])\n",
    "    f2Data=np.append(f2Data,data_dict[k][5][1])\n",
    "    f3Data=np.append(f3Data,data_dict[k][5][2])\n",
    "    f4Data=np.append(f4Data,data_dict[k][5][3])\n",
    "    aData=np.append(aData,data_dict[k][10])\n",
    "    vData=np.append(vData,data_dict[k][11])\n",
    "    iData=np.append(iData,data_dict[k][12])\n",
    "    sData=np.append(sData,data_dict[k][14]) \n",
    "    dData=np.append(dData,data_dict1[k][0])\n",
    "    stData=np.append(stData,data_dict[k][8])\n",
    "    sttData=np.append(sttData,data_dict[k][9])\n",
    "    tData.append(data_dict1[k][1])\n",
    "    f001.append(data_dict[k][15])\n",
    "    f002.append(data_dict[k][16])\n",
    "    f003.append(data_dict[k][17])\n",
    "    f005.append(data_dict[k][18])\n",
    "    f0075.append(data_dict[k][19])\n",
    "    f01.append(data_dict[k][20])\n",
    "    f015.append(data_dict[k][21])\n",
    "    f02.append(data_dict[k][22])\n",
    "    f025.append(data_dict[k][23])\n",
    "    f03.append(data_dict[k][24])\n",
    "    f04.append(data_dict[k][25])\n",
    "    f05.append(data_dict[k][26])\n",
    "    f075.append(data_dict[k][27])\n",
    "    f1.append(data_dict[k][28])\n",
    "    f15.append(data_dict[k][29])\n",
    "    f2.append(data_dict[k][30])\n",
    "    f3.append(data_dict[k][31])\n",
    "    f4.append(data_dict[k][32])\n",
    "    f5.append(data_dict[k][33])\n",
    "    f75.append(data_dict[k][34])\n",
    "    f10.append(data_dict[k][35])\n",
    "\n",
    "#saving all data in one npz file:\n",
    "np.savez('all data', mData=mData, rData=rData, hData=hData, f1Data=f1Data,f2Data=f2Data,f3Data=f3Data,f4Data=f4Data,\n",
    "         aData=aData,vData=vData, iData=iData, sData=sData,dData=dData,stData=stData,sttData=sttData,mwData=mwData,\n",
    "         rhData=rhData,fName=fName,tData=tData, f001=f001,f002=f002,f003=f003,f005=f005,f0075=f0075,\n",
    "         f01=f01,f015=f015,f02=f02,f03=f03,f04=f04,f05=f05,f075=f075,f1=f1,f15=f15,f2=f2,f3=f3,f4=f4,f5=f5,f75=f75,\n",
    "         f10=f10, MFAS=MFAS ) \n",
    "\n",
    "#choosing max measure from horizontal components:\n",
    "while i<len(mwData-1): \n",
    "    j=i\n",
    "    while j<len(mwData-1):\n",
    "        if j==285: break\n",
    "        if dData[i]==dData[j] and tData[i]==tData[j] and rData[i]==rData[j] and sttData[i]!=sttData[j] and sttData[i]!='SHZ' and sttData[i]!='EHZ' and sttData[j]!='SHZ' and sttData[j]!='EHZ' and sttData[i]!='HZ' and sttData[j]!='HZ':\n",
    "            #print(sttData[i])\n",
    "            #print(i)\n",
    "            if aData[i]>aData[j]: ij=i\n",
    "            else: ij=j\n",
    "            d1Data.append(dData[ij])\n",
    "            f11Data.append(f1Data[ij])\n",
    "            f21Data.append(f2Data[ij])\n",
    "            f31Data.append(f3Data[ij])\n",
    "            f41Data.append(f4Data[ij])\n",
    "            a1Data.append(aData[ij])\n",
    "            v1Data.append(vData[ij])\n",
    "            i1Data.append(iData[ij])\n",
    "            s1Data.append(np.log10(np.sqrt((10**sData[i])**2+(10**sData[j])**2)))\n",
    "            m1Data.append(mData[ij])\n",
    "            mw1Data.append(mwData[ij])\n",
    "            r1Data.append(rData[ij])\n",
    "            rh1Data.append(rhData[ij])\n",
    "            stt1Data.append(sttData[ij])\n",
    "            f001x.append(f001[ij])\n",
    "            f002x.append(f002[ij])\n",
    "            f003x.append(f003[ij])\n",
    "            f005x.append(f005[ij])\n",
    "            f0075x.append(f0075[ij])\n",
    "            f01x.append(f01[ij])\n",
    "            f015x.append(f015[ij])\n",
    "            f02x.append(f02[ij])\n",
    "            f025x.append(f025[ij])\n",
    "            f03x.append(f03[ij])\n",
    "            f04x.append(f04[ij])\n",
    "            f05x.append(f05[ij])\n",
    "            f075x.append(f075[ij])\n",
    "            f1x.append(f1[ij])\n",
    "            f15x.append(f15[ij])\n",
    "            f2x.append(f2[ij])\n",
    "            f3x.append(f3[ij])\n",
    "            f4x.append(f4[ij])\n",
    "            f5x.append(f5[ij])\n",
    "            f75x.append(f75[ij])\n",
    "            f10x.append(f10[ij])\n",
    "            i+=1  \n",
    "\n",
    "lon=[]\n",
    "lat=[]\n",
    "ID=[]\n",
    "Mw=[]\n",
    "for i in range (0, len(dData)):\n",
    "    lon.append(0)\n",
    "    lat.append(0)\n",
    "    ID.append('')\n",
    "    Mw.append(0)\n",
    "    \n",
    "#add earthquake info:\n",
    "for i in range(0,len(mData)):\n",
    "    if dData[i]=='22.08.2009' and mData[i]==5:\n",
    "        ID[i]='kEDYmxgB'\n",
    "        lat[i]='52,756'\n",
    "        lon[i]='144,042'\n",
    "        Mw[i]=4.8\n",
    "    if dData[i]=='16.03.2010' and mData[i]==5.7:\n",
    "        ID[i]='2OnYx7gy'\n",
    "        lat[i]='52,081'\n",
    "        lon[i]='142,175'\n",
    "        Mw[i]=5.8\n",
    "    if dData[i]=='09.07.2010' and mData[i]==5.1:\n",
    "        ID[i]='9EBmd1Mz'\n",
    "        lat[i]='52,114'\n",
    "        lon[i]='142,154'\n",
    "        Mw[i]=5\n",
    "    if dData[i]=='06.03.2011' and mData[i]==4.6:\n",
    "        ID[i]='QgpPLGgW'\n",
    "        lat[i]='52,102'\n",
    "        lon[i]='142,207'\n",
    "        Mw[i]=4.9\n",
    "    if dData[i]=='12.12.2011' and mData[i]==5.4:\n",
    "        ID[i]='yMKwJqMW'\n",
    "        lat[i]='50,688'\n",
    "        lon[i]='142,969'\n",
    "        Mw[i]=5.1\n",
    "    if dData[i]=='21.10.2012' and mData[i]==4.8:\n",
    "        ID[i]='xEw9o2Oy'\n",
    "        lat[i]='53,405'\n",
    "        lon[i]='142,55'\n",
    "        Mw[i]=4.9\n",
    "    if dData[i]=='19.02.2014' and mData[i]==5:\n",
    "        ID[i]='kEedbGMY'\n",
    "        lat[i]='52,15'\n",
    "        lon[i]='143,361'\n",
    "        Mw[i]=5.1\n",
    "    if dData[i]=='30.06.2014' and mData[i]==4.5:\n",
    "        ID[i]='WgvxrBMj'\n",
    "        lat[i]='51,57'\n",
    "        lon[i]='143,101'\n",
    "        Mw[i]=4.9\n",
    "    if dData[i]=='14.08.2016' and mData[i]==6.1:\n",
    "        ID[i]='QgpAn7OW'\n",
    "        lat[i]='50,351'\n",
    "        lon[i]='142,395'\n",
    "        Mw[i]=5.7\n",
    "    if dData[i]=='14.08.2016' and mData[i]==4.5:\n",
    "        ID[i]='lgbejpE7'\n",
    "        lat[i]='50,31'\n",
    "        lon[i]='142,344'\n",
    "        Mw[i]=4.6\n",
    "    if dData[i]=='15.08.2016' and mData[i]==5:\n",
    "        ID[i]='zErvpXEG'\n",
    "        lat[i]='50,376'\n",
    "        lon[i]='142,388'\n",
    "        Mw[i]=4.7\n",
    "    if dData[i]=='16.08.2016' and mData[i]==4.6:\n",
    "        ID[i]='vO4zDXEP'\n",
    "        lat[i]='50,355'\n",
    "        lon[i]='142,499'\n",
    "        Mw[i]=4.6\n",
    "    if dData[i]=='17.08.2016' and mData[i]==4.9:\n",
    "        ID[i]='KEXK05M0'\n",
    "        lat[i]='50,322'\n",
    "        lon[i]='142,435'\n",
    "        Mw[i]=4.6\n",
    "    if dData[i]=='17.08.2016' and mData[i]==4.5:\n",
    "        ID[i]='zO9L5egK'\n",
    "        lat[i]='50,376'\n",
    "        lon[i]='142,446'\n",
    "        Mw[i]=4.6\n",
    "    if dData[i]=='20.08.2016' and mData[i]==4.4:\n",
    "        ID[i]='kEePppMY'\n",
    "        lat[i]='50,213'\n",
    "        lon[i]='142,816'\n",
    "        Mw[i]=4.5\n",
    "    if dData[i]=='07.04.2017' and mData[i]==4.1:\n",
    "        ID[i]='xEwjZBMy'\n",
    "        lat[i]='46,93'\n",
    "        lon[i]='142,607'\n",
    "        Mw[i]=''\n",
    "    if dData[i]=='23.04.2017' and mData[i]==5.1:\n",
    "        ID[i]='KEXKBvM3'\n",
    "        lat[i]='46,178'\n",
    "        lon[i]='141,976'\n",
    "        Mw[i]=5.2\n",
    "    if dData[i]=='08.06.2017' and mData[i]==4.3:\n",
    "        ID[i]='WgvnwNgj'\n",
    "        lat[i]='46,948'\n",
    "        lon[i]='142,572'\n",
    "        Mw[i]=4.4\n",
    "    if dData[i]=='07.10.2018' and mData[i]==4.1:\n",
    "        ID[i]='LbdmJPAE'\n",
    "        lat[i]='51,324'\n",
    "        lon[i]='142,167'\n",
    "        Mw[i]=4.7\n",
    "    if dData[i]=='23.01.2020' and mData[i]==4.4:\n",
    "        ID[i]='xAm2x7B8'\n",
    "        lat[i]='46,563'\n",
    "        lon[i]='142,456'\n",
    "        Mw[i]=4.4\n",
    "    if dData[i]=='13.09.2020' and mData[i]==5:\n",
    "        ID[i]='EAWDxgBk'\n",
    "        lat[i]='48,963'\n",
    "        lon[i]='142,032'\n",
    "        Mw[i]=5\n",
    "    if dData[i]=='08.11.2020' and mData[i]==4.7:\n",
    "        ID[i]='oBOjzMAN'\n",
    "        lat[i]='52,992'\n",
    "        lon[i]='142,427'\n",
    "        Mw[i]=4.6\n",
    "    if dData[i]=='28.01.2021' and mData[i]==4.2:\n",
    "        ID[i]='qB24vXbY'\n",
    "        lat[i]='51,854'\n",
    "        lon[i]='143,033'\n",
    "        Mw[i]=4.1\n",
    "    if dData[i]=='18.04.2021' and mData[i]==4.5:\n",
    "        ID[i]='NBxeolZJ'\n",
    "        lat[i]='50,87'\n",
    "        lon[i]='142,621'\n",
    "        Mw[i]=4.2\n",
    "    if dData[i]=='17.06.2021' and mData[i]==4.3:\n",
    "        ID[i]='Vb7WQObM'\n",
    "        lat[i]='47,237'\n",
    "        lon[i]='142,649'\n",
    "        Mw[i]=''\n",
    "    if dData[i]=='28.12.2021' and mData[i]==4.1:\n",
    "        ID[i]='yBYzVYZn'\n",
    "        lat[i]='50,523'\n",
    "        lon[i]='143,921'\n",
    "        Mw[i]=4.5\n",
    "    if dData[i]=='05.02.2022' and mData[i]==5.5:\n",
    "        ID[i]='dBGGg5By'\n",
    "        lat[i]='52,527'\n",
    "        lon[i]='143,452'\n",
    "        Mw[i]=5.2\n",
    "    if dData[i]=='09.02.2022' and mData[i]==4.1:\n",
    "        ID[i]='6AqJQ8Br'\n",
    "        lat[i]='46,82'\n",
    "        lon[i]='142,115'\n",
    "        Mw[i]=''\n",
    "\n",
    "#saving all intensity measures to one excel file:\n",
    "df = pd.DataFrame()\n",
    "df = df.append(pd.DataFrame({\n",
    "                            'ID': ID,\n",
    "                            'Date': dData,\n",
    "                            'Time': tData,\n",
    "                            'Latitude': lat,\n",
    "                            'Longitude': lon,\n",
    "                            'Depth, km': hData,\n",
    "                            'R_epi, km': rData,\n",
    "                            'R_hyp, km': rhData,\n",
    "                            'ML': mData,\n",
    "                            'Mw (USGS)': Mw,\n",
    "                            'Mw (calculation)': mwData,\n",
    "                            'PGA, cm/s²': aData,\n",
    "                            'PGV, cm/s': vData,\n",
    "                            'Ia, m/s': iData,\n",
    "                            'MFAS, m/s': MFAS,\n",
    "                            'FAS (0.01), m/s': f001,\n",
    "                            'FAS (0.02), m/s': f002,\n",
    "                            'FAS (0.03), m/s': f003,\n",
    "                            'FAS (0.05), m/s': f005,\n",
    "                            'FAS (0.075), m/s': f0075,\n",
    "                            'FAS (0.1), m/s': f01,\n",
    "                            'FAS (0.2), m/s': f02,\n",
    "                            'FAS (0.25), m/s': f025,\n",
    "                            'FAS (0.3), m/s': f03,\n",
    "                            'FAS (0.4), m/s': f04,\n",
    "                            'FAS (0.5), m/s': f05,\n",
    "                            'FAS (0.75), m/s': f075,\n",
    "                            'FAS (1), m/s': f1,\n",
    "                            'FAS (2), m/s': f2,\n",
    "                            'FAS (3), m/s': f3,\n",
    "                            'FAS (4), m/s': f4,\n",
    "                            'FAS (5), m/s': f5,\n",
    "                            'FAS (7.5), m/s': f75,\n",
    "                            'FAS (10), m/s': f10,\n",
    "                            'FIV3 (0.01)': f1Data,\n",
    "                            'FIV3 (0.2)': f2Data,\n",
    "                            'FIV3 (1)': f3Data,\n",
    "                            'FIV3 (3)': f4Data,\n",
    "                            'Код станции': stData,\n",
    "                            'Канал': sttData,\n",
    "                            'Имя файла': fName\n",
    "                             }), ignore_index=True)\n",
    "df.to_excel('./all data zne.xlsx')\n",
    "len(mData)\n",
    "\n",
    "#calculate gmpe coefficients :\n",
    "allData=[]\n",
    "allData.append(f1Data)\n",
    "allData.append(f2Data)\n",
    "allData.append(f3Data)\n",
    "allData.append(f4Data)\n",
    "allData.append(vData)\n",
    "allData.append(aData)\n",
    "allData.append(iData)\n",
    "allData.append(sData)\n",
    "def log10ValRh(m1): #function for logarithm massives\n",
    "    res=[]\n",
    "    for i in range(0,len(m1)):\n",
    "        res.append(np.log10(m1[i]))\n",
    "    return res\n",
    "def func(X, a, b, c, d):\n",
    "    x1,x2=X\n",
    "    return np.multiply(a,x1) - np.multiply(b,np.log10(x2)) - np.multiply(c,x2) + d\n",
    "def func1(X, a, b, c, d):\n",
    "    x1,x2=X\n",
    "    return np.multiply(a,x1) - np.multiply(b,np.log10(x2)) - np.multiply(c,x2) + d\n",
    "logs=[]\n",
    "RMSE=[]\n",
    "coeffs=[]\n",
    "perr=[]\n",
    "logs.append(log10ValRh(f11Data)) #FIV3 T=0.01\n",
    "logs.append(log10ValRh(f21Data)) #FIV3 T=0.2\n",
    "logs.append(log10ValRh(f31Data)) #FIV3 T=1\n",
    "logs.append(log10ValRh(f41Data)) #FIV3 T=3\n",
    "logs.append(log10ValRh(v1Data)) #Velocity\n",
    "logs.append(log10ValRh(a1Data)) #Acceleration\n",
    "logs.append(log10ValRh(i1Data)) #Arias Intentity\n",
    "logs.append(s1Data) #Raw Spectrum\n",
    "for i in range (0,len(logs)):\n",
    "    yData=logs[i]\n",
    "    xData=mw1Data,rh1Data\n",
    "    if i==6:\n",
    "        popt, pcov = curve_fit(func1, xData, yData)\n",
    "    else:\n",
    "        popt, pcov = curve_fit(func, xData, yData)\n",
    "    coeffs.append(popt)\n",
    "    print(coeffs[i])\n",
    "    perr.append(np.sqrt(np.diag(pcov)))\n",
    "    print(perr[i])\n",
    "    modelPredictions = func(xData, *popt) \n",
    "    absError = modelPredictions - yData\n",
    "    SE = np.square(absError) # squared errors\n",
    "    MSE = np.mean(SE) # mean squared errors\n",
    "    RMSE.append(np.sqrt(MSE))\n",
    "    print(RMSE[i])\n",
    "    from sklearn.metrics import r2_score\n",
    "    r2.append(round(r2_score(yData, modelPredictions),3)) #calculate R² metrica\n",
    "    print(r2[i])\n",
    "a=[]\n",
    "k=[]\n",
    "b=[]\n",
    "c=[]\n",
    "rmse=[]\n",
    "unit=[\"lg FIV3(Mw), T=0.01 [cm/s]\",\"lg FIV3(Mw), T=0.2 [cm/s]\",\"lg FIV3(Mw), T=1 [cm/s]\",\"lg FIV3(Mw), T=3 [cm/s]\",\"lg PGV(Mw) [cm/s]\",\"lg PGA(Mw) [cm/s²]\",\"lg Iₐ(Mw) [m/s]\",\"lg MFAS(Mw) [m/s]\"]\n",
    "for i in range (0,len(coeffs)):\n",
    "    a.append(str(round(coeffs[i][0],2))+\"±\"+str(round(perr[i][0],2)))\n",
    "    k.append(str(round(coeffs[i][1],2))+\"±\"+str(round(perr[i][1],2)))\n",
    "    b.append(str(round(coeffs[i][2],4))+\"±\"+str(round(perr[i][2],4)))\n",
    "    if i==7: c.append(str(round(coeffs[i][3]-9,2))+\"±\"+str(round(perr[i][3],2)))\n",
    "    else: c.append(str(round(coeffs[i][3],2))+\"±\"+str(round(perr[i][3],2)))\n",
    "    rmse.append(str(round(RMSE[i],3)))\n",
    "df = pd.DataFrame()\n",
    "#saving coefficients to excel file:\n",
    "df = df.append(pd.DataFrame({ 'unit': unit,\n",
    "                            'a': a,\n",
    "                            'k': k,\n",
    "                            'b': b,  \n",
    "                            'c': c, \n",
    "                            'σ': rmse\n",
    "                            \n",
    "                             }), ignore_index=True)\n",
    "                    \n",
    "           \n",
    "df.to_excel('./coeffs abcd(mw).xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
